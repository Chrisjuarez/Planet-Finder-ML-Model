{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c65fa2a",
   "metadata": {},
   "source": [
    "# Multiple ML Classifiers\n",
    "\n",
    "Names: Christian Juarez, Analiese Gonzalez, Alyssa Amancio\n",
    "\n",
    "This notebook implements four or more different ML classifiers for the planet-host prediction problem using the preprocessed Kepler features.\n",
    "\n",
    "- Target: `label_lenient` (planet-host vs non-host)\n",
    "- Features: all engineered columns from `table_v1.parquet`\n",
    "- Split: pre-defined `train/val/test` from `split_v1.csv`\n",
    "\n",
    "Note:This submission focuses only on implementing and fitting the models. Full evaluation, model comparison, and hyperparameter tuning will be done in the next assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213278e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>teff</th>\n",
       "      <th>logg</th>\n",
       "      <th>feh</th>\n",
       "      <th>radius</th>\n",
       "      <th>mass</th>\n",
       "      <th>kepmag</th>\n",
       "      <th>rrmscdpp03p0</th>\n",
       "      <th>rrmscdpp06p0</th>\n",
       "      <th>rrmscdpp12p0</th>\n",
       "      <th>...</th>\n",
       "      <th>detection_eff</th>\n",
       "      <th>rrmscdpp03p0_log</th>\n",
       "      <th>rrmscdpp06p0_log</th>\n",
       "      <th>rrmscdpp12p0_log</th>\n",
       "      <th>nconfp</th>\n",
       "      <th>nkoi</th>\n",
       "      <th>ntce</th>\n",
       "      <th>label_strict</th>\n",
       "      <th>label_lenient</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000785</td>\n",
       "      <td>5333.0</td>\n",
       "      <td>4.616</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.635</td>\n",
       "      <td>15.749</td>\n",
       "      <td>445.410</td>\n",
       "      <td>499.980</td>\n",
       "      <td>589.300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>6.101238</td>\n",
       "      <td>6.216566</td>\n",
       "      <td>6.380631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000797</td>\n",
       "      <td>6289.0</td>\n",
       "      <td>4.270</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.968</td>\n",
       "      <td>13.994</td>\n",
       "      <td>80.767</td>\n",
       "      <td>60.264</td>\n",
       "      <td>45.939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>4.403874</td>\n",
       "      <td>4.115192</td>\n",
       "      <td>3.848849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000800</td>\n",
       "      <td>5692.0</td>\n",
       "      <td>4.547</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.965</td>\n",
       "      <td>15.379</td>\n",
       "      <td>226.348</td>\n",
       "      <td>184.595</td>\n",
       "      <td>158.220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>5.426482</td>\n",
       "      <td>5.223567</td>\n",
       "      <td>5.070287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000823</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>4.377</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1.169</td>\n",
       "      <td>1.191</td>\n",
       "      <td>15.558</td>\n",
       "      <td>181.468</td>\n",
       "      <td>148.879</td>\n",
       "      <td>132.140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>5.206575</td>\n",
       "      <td>5.009828</td>\n",
       "      <td>4.891401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000827</td>\n",
       "      <td>5648.0</td>\n",
       "      <td>4.559</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.939</td>\n",
       "      <td>14.841</td>\n",
       "      <td>124.834</td>\n",
       "      <td>92.096</td>\n",
       "      <td>67.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>4.834964</td>\n",
       "      <td>4.533631</td>\n",
       "      <td>4.227301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid    teff   logg   feh  radius   mass  kepmag  rrmscdpp03p0  \\\n",
       "0  10000785  5333.0  4.616 -1.00   0.650  0.635  15.749       445.410   \n",
       "1  10000797  6289.0  4.270 -0.44   1.195  0.968  13.994        80.767   \n",
       "2  10000800  5692.0  4.547 -0.04   0.866  0.965  15.379       226.348   \n",
       "3  10000823  6580.0  4.377 -0.16   1.169  1.191  15.558       181.468   \n",
       "4  10000827  5648.0  4.559 -0.10   0.841  0.939  14.841       124.834   \n",
       "\n",
       "   rrmscdpp06p0  rrmscdpp12p0  ...  detection_eff  rrmscdpp03p0_log  \\\n",
       "0       499.980       589.300  ...       0.000054          6.101238   \n",
       "1        60.264        45.939  ...       0.001693          4.403874   \n",
       "2       184.595       158.220  ...       0.000264          5.426482   \n",
       "3       148.879       132.140  ...       0.000590          5.206575   \n",
       "4        92.096        67.532  ...       0.000517          4.834964   \n",
       "\n",
       "   rrmscdpp06p0_log  rrmscdpp12p0_log  nconfp  nkoi  ntce  label_strict  \\\n",
       "0          6.216566          6.380631       0     0     2             0   \n",
       "1          4.115192          3.848849       0     0     0             0   \n",
       "2          5.223567          5.070287       0     0     0             0   \n",
       "3          5.009828          4.891401       0     0     0             0   \n",
       "4          4.533631          4.227301       0     0     0             0   \n",
       "\n",
       "   label_lenient  split  \n",
       "0              0  train  \n",
       "1              0  train  \n",
       "2              0   test  \n",
       "3              0    val  \n",
       "4              0  train  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Adjust ROOT. When this notebook lives in notebooks/\n",
    "# the data folder is at ../data/processed/..\n",
    "ROOT = Path(\"/Users/chrisjuarez/CPSC483_ML_Project\") \n",
    "\n",
    "X_full = pd.read_parquet(ROOT / 'data/processed/features/table_v1.parquet')\n",
    "y_full = pd.read_csv(ROOT / 'data/processed/labels/labels_v1.csv')\n",
    "splits = pd.read_csv(ROOT / 'data/processed/splits/split_v1.csv')\n",
    "\n",
    "# Merge into a single DataFrame\n",
    "df = X_full.merge(y_full, on='kepid').merge(splits, on='kepid')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065da342",
   "metadata": {},
   "source": [
    "## Train / Val / Test Split\n",
    "\n",
    "We use the existing `split` column to create train, validation, and test sets. The prediction target is `label_lenient` (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6982fc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105532, 27), (15077, 27), (30153, 27))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target column (binary classification)\n",
    "target_col = 'label_lenient'\n",
    "\n",
    "# Features: drop non-feature columns\n",
    "non_feature_cols = ['split', 'label_lenient', 'label_strict'] # add any other features to reduce if needed \n",
    "feature_cols = [c for c in df.columns if c not in non_feature_cols]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "X_train = X[df['split'] == 'train']\n",
    "y_train = y[df['split'] == 'train']\n",
    "\n",
    "X_val = X[df['split'] == 'val']\n",
    "y_val = y[df['split'] == 'val']\n",
    "\n",
    "X_test = X[df['split'] == 'test']\n",
    "y_test = y[df['split'] == 'test']\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55da2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a3123",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression (with Standardization)\n",
    "\n",
    "A linear classification model that estimates the probability of a star being a planet host. We use an L2-penalized logistic regression with standardized inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e893c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model fitted.\n"
     ]
    }
   ],
   "source": [
    "log_reg_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('log_reg', LogisticRegression(max_iter=200, n_jobs=-1))\n",
    "])\n",
    "\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "print('Logistic Regression model fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4c524",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier\n",
    "\n",
    "An ensemble of decision trees trained with bootstrap aggregation (bagging). This is similar to the model already used in the earlier notebook, but we keep it here as one of the required ML techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c337921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model fitted.\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "print('Random Forest model fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc5d76",
   "metadata": {},
   "source": [
    "### 3. Gradient Boosting Classifier\n",
    "\n",
    "A boosting-based ensemble that builds trees sequentially, where each new tree tries to correct the errors of the previous ensemble. This often performs well on tabular data with structured features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be863d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting model fitted.\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "print('Gradient Boosting model fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2655f",
   "metadata": {},
   "source": [
    "### 4. K-Nearest Neighbors (KNN) Classifier\n",
    "\n",
    "A simple instance-based learner that classifies each sample based on the majority label among its `k` nearest neighbors in feature space (after scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7dc08b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model fitted.\n"
     ]
    }
   ],
   "source": [
    "knn_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=15))\n",
    "])\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "print('KNN model fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e6b8e",
   "metadata": {},
   "source": [
    "# We can delete whats below just checking to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a232d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce4c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, clf, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    print(f\"\\n== {name} ==\")\n",
    "    \n",
    "    splits = {\n",
    "        \"Train\": (X_train, y_train),\n",
    "        \"Val\":   (X_val,   y_val),\n",
    "        \"Test\":  (X_test,  y_test),\n",
    "    }\n",
    "    \n",
    "    for split_name, (X_split, y_split) in splits.items():\n",
    "        y_pred = clf.predict(X_split)\n",
    "        acc = accuracy_score(y_split, y_pred)\n",
    "        \n",
    "        y_score = None\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_split)[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_split)\n",
    "        \n",
    "        if y_score is not None:\n",
    "            auc = roc_auc_score(y_split, y_score)\n",
    "            print(f\"{split_name:5s} | accuracy = {acc:.4f} | ROC AUC = {auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"{split_name:5s} | accuracy = {acc:.4f} | ROC AUC = N/A (no scores)\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nTest set classification report:\")\n",
    "    print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1714a9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Logistic Regression ==\n",
      "Train | accuracy = 0.9911 | ROC AUC = 0.9973\n",
      "Val   | accuracy = 0.9899 | ROC AUC = 0.9965\n",
      "Test  | accuracy = 0.9916 | ROC AUC = 0.9975\n",
      "\n",
      "Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     29428\n",
      "           1       0.93      0.70      0.80       725\n",
      "\n",
      "    accuracy                           0.99     30153\n",
      "   macro avg       0.96      0.85      0.90     30153\n",
      "weighted avg       0.99      0.99      0.99     30153\n",
      "\n",
      "\n",
      "== Random Forest ==\n",
      "Train | accuracy = 1.0000 | ROC AUC = 1.0000\n",
      "Val   | accuracy = 0.9910 | ROC AUC = 0.9974\n",
      "Test  | accuracy = 0.9918 | ROC AUC = 0.9978\n",
      "\n",
      "Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     29428\n",
      "           1       0.91      0.73      0.81       725\n",
      "\n",
      "    accuracy                           0.99     30153\n",
      "   macro avg       0.95      0.87      0.90     30153\n",
      "weighted avg       0.99      0.99      0.99     30153\n",
      "\n",
      "\n",
      "== Gradient Boosting ==\n",
      "Train | accuracy = 0.9920 | ROC AUC = 0.9981\n",
      "Val   | accuracy = 0.9904 | ROC AUC = 0.9972\n",
      "Test  | accuracy = 0.9920 | ROC AUC = 0.9979\n",
      "\n",
      "Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     29428\n",
      "           1       0.94      0.71      0.81       725\n",
      "\n",
      "    accuracy                           0.99     30153\n",
      "   macro avg       0.97      0.85      0.90     30153\n",
      "weighted avg       0.99      0.99      0.99     30153\n",
      "\n",
      "\n",
      "== K-Nearest Neighbors ==\n",
      "Train | accuracy = 0.9920 | ROC AUC = 0.9979\n",
      "Val   | accuracy = 0.9901 | ROC AUC = 0.9913\n",
      "Test  | accuracy = 0.9916 | ROC AUC = 0.9948\n",
      "\n",
      "Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     29428\n",
      "           1       0.91      0.72      0.80       725\n",
      "\n",
      "    accuracy                           0.99     30153\n",
      "   macro avg       0.95      0.86      0.90     30153\n",
      "weighted avg       0.99      0.99      0.99     30153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\":      log_reg_clf,\n",
    "    \"Random Forest\":           rf_clf,\n",
    "    \"Gradient Boosting\":       gb_clf,\n",
    "    \"K-Nearest Neighbors\":     knn_clf,   # add your model if you want to see its output\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    evaluate_model(\n",
    "        name,\n",
    "        clf,\n",
    "        X_train, y_train,\n",
    "        X_val,   y_val,\n",
    "        X_test,  y_test,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
